{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657b94b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"deepcontractor/supreme-court-judgment-prediction\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01338b94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to your dataset\n",
    "dataset_path = \"/root/.cache/kagglehub/datasets/deepcontractor/supreme-court-judgment-prediction/versions/1\"\n",
    "\n",
    "# List all files and folders\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    print(f\"\\nüìÅ Directory: {root}\")\n",
    "    for file in files:\n",
    "        print(f\"   üìÑ {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474bed6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"/root/.cache/kagglehub/datasets/deepcontractor/supreme-court-judgment-prediction/versions/1/justice.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56165d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c30b5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "## for data\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk## for language detection\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36d0c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df1.drop(columns=['Unnamed: 0', 'docket','name','first_party','second_party', 'issue_area',\n",
    "                 'facts_len', 'majority_vote', 'minority_vote', 'href', 'ID','term'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81860a78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_cat = df1[['decision_type', 'disposition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c5543",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_target = df1['first_party_winner']\n",
    "df_nlp = df1['facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd224cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_cat.reset_index(drop=True, inplace=True)\n",
    "df_target.reset_index(drop=True, inplace=True)\n",
    "df_nlp.reset_index(drop=True, inplace=True)\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_target= label_encoder.fit_transform(df_target)\n",
    "df_target1 = pd.DataFrame(df_target, columns=['first_party_winner'])\n",
    "df_target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43254324",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "frames = [df_cat, df_target1]\n",
    "df_concat = pd.concat(frames, axis=1, join='inner')\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4a087",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_nlp1 = pd.DataFrame(df_nlp, columns=['facts'])\n",
    "df_nlp1['facts'] = df_nlp1['facts'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "df_nlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5e875",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "corpus = df_nlp1[\"facts\"]\n",
    "\n",
    "import nltk\n",
    "# Removed the download for punkt_tab as it was already downloaded in the previous run\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "ps = nltk.stem.porter.PorterStemmer()\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "\n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in\n",
    "                    lst_stopwords]\n",
    "\n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "\n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "\n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n",
    "df_nlp1[\"facts_clean\"] = df_nlp1[\"facts\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))\n",
    "df_nlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d6ba0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_nlp2 = pd.concat([df_nlp1,df_target1['first_party_winner']],axis=1, join='inner')\n",
    "df_nlp2[\"first_party_winner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290cd4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Separate the classes\n",
    "class_1 = df_nlp2[df_nlp2[\"first_party_winner\"] == 1]\n",
    "class_0 = df_nlp2[df_nlp2[\"first_party_winner\"] == 0]\n",
    "\n",
    "# Undersample class 1 to match count of class 0 (1031)\n",
    "class_1_under = class_1.sample(len(class_0), random_state=42)\n",
    "\n",
    "# Combine the two classes\n",
    "df_nlp2 = pd.concat([class_1_under, class_0], axis=0)\n",
    "\n",
    "# Shuffle the combined DataFrame\n",
    "df_nlp2 = df_nlp2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Confirm balanced data\n",
    "print(df_nlp2[\"first_party_winner\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c3c31",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_nlp2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897790d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9c6c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df1.drop(columns=['facts'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09410c75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db97e29",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert labels to binary: True ‚Üí 1, False ‚Üí 0\n",
    "df1['label'] = df1['first_party_winner'].astype(int)\n",
    "df1['text'] = df1['facts_clean']\n",
    "\n",
    "# Split into train/test\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df1['text'].tolist(), df1['label'].tolist(), test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96d791",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count in training labels\n",
    "train_distribution = Counter(train_labels)\n",
    "print(\"Training Label Distribution:\", train_distribution)\n",
    "\n",
    "# Count in validation labels\n",
    "val_distribution = Counter(val_labels)\n",
    "print(\"Validation Label Distribution:\", val_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694c52a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "# ‚úÖ Load better tokenizer: Legal RoBERTa\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "\n",
    "# Tokenize text data\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# ‚úÖ Define Dataset Class\n",
    "class CourtDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Dataset objects\n",
    "train_dataset = CourtDataset(train_encodings, train_labels)\n",
    "val_dataset = CourtDataset(val_encodings, val_labels)\n",
    "\n",
    "# ‚úÖ Define Evaluation Metrics\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "# ‚úÖ Load Legal-RoBERTa Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# ‚úÖ Define Better Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# ‚úÖ Trainer with metrics\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# üèãÔ∏è Start Training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f824ae4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "def predict_outcome(text, model, tokenizer):\n",
    "    # Clean the text\n",
    "    text_clean = utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords)\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text_clean, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    # Move to device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = softmax(logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "        confidence = probs[0][predicted_class].item()\n",
    "\n",
    "    return predicted_class, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73631f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def suggest_legal_actions(facts):\n",
    "    prompt = f\"\"\"You are an expert Indian legal advisor. Carefully study the case facts below, and suggest **three concrete legal actions** the First Party should take to improve their chances of winning in court. Be specific and legally sound.\n",
    "\n",
    "Case Facts:\n",
    "{facts}\n",
    "\n",
    "Suggestions:\"\"\"\n",
    "\n",
    "    # Load the FLAN-T5 model\n",
    "    suggestions_generator = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"google/flan-t5-large\",\n",
    "        device=0  # use -1 if you're on CPU\n",
    "    )\n",
    "\n",
    "    # Generate suggestion\n",
    "    result = suggestions_generator(\n",
    "        prompt,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.8,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "\n",
    "    # Extract and return suggestions\n",
    "    suggestions = result[0]['generated_text'].strip()\n",
    "    return suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40f645",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_facts = \"i killed my wife\"\n",
    "\n",
    "# ‚úÖ Call the function\n",
    "output = suggest_legal_actions(input_facts)\n",
    "\n",
    "# üì§ Print the output\n",
    "print(\"üîé Suggested Legal Actions:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47d32d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def suggest_punishment_article(facts):\n",
    "    prompt = f\"\"\"You are a legal expert. Given the following facts from a Supreme Court case, what is the most likely Article or IPC section the first party may be punished under if they lose?\n",
    "\n",
    "Case Facts:\n",
    "{facts}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Use a language model (e.g., GPT)\n",
    "    from transformers import pipeline\n",
    "    article_generator = pipeline(\"text-generation\", model=\"gpt2\")  # Replace with better legal model if available\n",
    "\n",
    "    result = article_generator(prompt, max_length=100, do_sample=True)[0]['generated_text']\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b4988",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def legal_superbot(facts, model, tokenizer):\n",
    "    print(\"üîç Predicting outcome...\")\n",
    "    outcome, confidence = predict_outcome(facts, model, tokenizer)\n",
    "\n",
    "    print(\"\\nüõ°Ô∏è Suggestions to help your case:\")\n",
    "    suggestions = suggest_legal_actions(facts)\n",
    "\n",
    "    print(\"\\nüö® If case is lost, possible punishment under:\")\n",
    "    article = suggest_punishment_article(facts)\n",
    "\n",
    "    # Format confidence as %\n",
    "    confidence_percent = round(confidence * 100, 2)\n",
    "\n",
    "    # Outcome message with confidence\n",
    "    outcome_msg = (\n",
    "        f\"First party WINS ‚úÖ (Confidence: {confidence_percent}%)\"\n",
    "        if outcome == 1 else\n",
    "        f\"First party LOSES ‚ùå (Confidence: {confidence_percent}%)\"\n",
    "    )\n",
    "\n",
    "    result = {\n",
    "        \"Outcome\": outcome_msg,\n",
    "        \"Suggestions\": suggestions,\n",
    "        \"Likely Article/IPC if Lost\": article\n",
    "    }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5606d7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_facts = \"\"\"\n",
    "The petitioner, a government employee, was found guilty of accepting a bribe of ‚Çπ50,000 in exchange for approving a tender. The CBI filed a chargesheet, and departmental proceedings were initiated.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2b2f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "result = legal_superbot(test_facts, model, tokenizer)\n",
    "\n",
    "# Display nicely\n",
    "for key, value in result.items():\n",
    "    print(f\"\\nüîπ {key}:\")\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097af7b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Save model and tokenizer\n",
    "trainer.save_model(\"legalbert_model\")  # Saves model\n",
    "tokenizer.save_pretrained(\"legalbert_model\")  # Saves tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ece650",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Save model and tokenizer\n",
    "trainer.save_model(\"legalbert_model\")  # Saves model\n",
    "tokenizer.save_pretrained(\"legalbert_model\")  # Saves tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49525aee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!zip -r legalbert_model.zip legalbert_model/\n",
    "from google.colab import files\n",
    "files.download(\"legalbert_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b55985",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Install transformers (if not already)\n",
    "!pip install transformers --upgrade -q\n",
    "!pip install accelerate --upgrade -q\n",
    "\n",
    "# ‚úÖ Import Required Modules\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# ‚úÖ Load the Legal GPT-2 Style Model\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"SkolkovoInstitute/rugpt3small_based_on_gpt2\",\n",
    "    tokenizer=\"SkolkovoInstitute/rugpt3small_based_on_gpt2\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# ‚úÖ Define Prompt\n",
    "facts = \"\"\"\n",
    "The defendant failed to deliver the shipment of machinery on the agreed date despite multiple reminders. The first party suffered financial losses due to project delays.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"You are a legal assistant. Given the case facts below, suggest the best possible actions the first party can take to improve their chances of winning in court.\n",
    "\n",
    "Case Facts:\n",
    "{facts}\n",
    "\n",
    "Suggestions:\"\"\"\n",
    "\n",
    "# ‚úÖ Generate Suggestions\n",
    "output = generator(prompt, max_length=200, do_sample=True, temperature=0.8)[0][\"generated_text\"]\n",
    "\n",
    "# ‚úÖ Extract and Display Suggestions\n",
    "suggestions = output.split(\"Suggestions:\")[-1].strip()\n",
    "print(\"üìå Suggestions for First Party:\\n\")\n",
    "print(suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d1e89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./my_model/\")\n",
    "tokenizer.save_pretrained(\"./my_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7223f92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def legal_superbot(facts, model, tokenizer):\n",
    "    print(\"üîç Predicting outcome...\")\n",
    "    outcome, confidence = predict_outcome(facts, model, tokenizer)\n",
    "\n",
    "    print(\"\\nüõ°Ô∏è Suggestions to help your case:\")\n",
    "    suggestions = suggest_legal_actions(facts)\n",
    "\n",
    "    print(\"\\nüö® If case is lost, possible punishment under:\")\n",
    "    article = suggest_punishment_article(facts)\n",
    "\n",
    "    # Format confidence as %\n",
    "    confidence_percent = round(confidence * 100, 2)\n",
    "\n",
    "    # Outcome message with confidence\n",
    "    outcome_msg = (\n",
    "        f\"First party WINS ‚úÖ (Confidence: {confidence_percent}%)\"\n",
    "        if outcome == 1 else\n",
    "        f\"First party LOSES ‚ùå (Confidence: {confidence_percent}%)\"\n",
    "    )\n",
    "\n",
    "    result = {\n",
    "        \"Outcome\": outcome_msg,\n",
    "        \"Suggestions\": suggestions,\n",
    "        \"Likely Article/IPC if Lost\": article\n",
    "    }\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
